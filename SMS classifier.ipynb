{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51506952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f1631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset1 = pd.read_csv(r\"C:\\Users\\HUPSIKA CHARY\\Downloads\\SMS_Classify\\SMS_Classify\\spam.csv\", encoding='latin-1')\n",
    "df = dataset1[['v2', 'v1']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90b3457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\HUPSIKA\n",
      "[nltk_data]     CHARY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\HUPSIKA\n",
      "[nltk_data]     CHARY\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\HUPSIKA\n",
      "[nltk_data]     CHARY\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44609ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the lemmatizer and stopwords\n",
    "lemma = WordNetLemmatizer()\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1b9b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the tokenizer function\n",
    "def tokenizer(row):\n",
    "    row = row.lower()\n",
    "    row = re.sub(r'[^a-zA-Z\\s]', ' ', row)\n",
    "    row = ' '.join([word for word in row.split() if word not in stopwords_set])\n",
    "    row = ' '.join([lemma.lemmatize(word) for word in row.split()])\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20488183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the tokenizer function to the 'text' column\n",
    "df.loc[:, 'v2'] = df['v2'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e92958b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(df['v2'], df['v1'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c7936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization\n",
    "vt = TfidfVectorizer(max_features=50000, lowercase=False, ngram_range=(1, 2))\n",
    "x_train = vt.fit_transform(x_train)\n",
    "x_test = vt.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f227cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrames with meaningful column names\n",
    "x_train_df = pd.DataFrame(x_train.toarray(), columns=vt.get_feature_names_out())\n",
    "x_test_df = pd.DataFrame(x_test.toarray(), columns=vt.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85347a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "model = MultinomialNB()\n",
    "model.fit(x_train, y_train)\n",
    "pred = model.predict(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23de50ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix on Training Set:\n",
      "[[3860    0]\n",
      " [  97  500]]\n",
      "Accuracy on Training Set: 0.9782364819385236\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation on training set\n",
    "cf = confusion_matrix(y_train, pred)\n",
    "ac = accuracy_score(y_train, pred)\n",
    "print(\"Confusion Matrix on Training Set:\")\n",
    "print(cf)\n",
    "print(\"Accuracy on Training Set:\", ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8997b32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting for a mail\n",
    "text = \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\"\n",
    "text = tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0df8623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming vt is the vectorizer trained during training\n",
    "text_vectorized = vt.transform([text]).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "444562a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the dimensions are consistent with the model's expectations\n",
    "if text_vectorized.shape[1] != x_train_df.shape[1]:\n",
    "    raise ValueError(\"Mismatch in the number of features between vectorizer and model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8b4a1245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for the mail: ['spam']\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "pred1 = model.predict(text_vectorized)\n",
    "print(\"Prediction for the mail:\", pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9485f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
